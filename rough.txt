import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def plot_rotation_matrix(R, ax, origin=np.array([0, 0, 0]), length=1.0, label=None):
    """
    Visualizes a single rotation matrix as basis vectors in 3D space.
    
    Parameters:
    R (np.array): 3x3 rotation matrix.
    ax (Axes3D): 3D axis to plot on.
    origin (np.array): Origin of the basis vectors.
    length (float): Length of the basis vectors.
    label (str): Label for the basis vectors.
    """
    colors = ['r', 'g', 'b']
    labels = ['x', 'y', 'z'] if label is None else label
    
    for i in range(3):
        ax.quiver(*origin, *R[:, i]*length, color=colors[i], label=f'{labels[i]}-axis')
    
def plot_multiple_rotation_matrices(rotation_matrices, position_diff, axis='x',figsize=(10,10),lims = [-10,10]):
    """
    Visualizes multiple rotation matrices with fixed position differences.
    
    Parameters:
    rotation_matrices (list of np.array): List of 3x3 rotation matrices.
    position_diff (float): Fixed positional offset.
    axis (str): Axis along which the offset is applied ('x', 'y', or 'z').
    """
    fig = plt.figure(figsize=figsize)
    ax = fig.add_subplot(111, projection='3d')
    ax.set_xlim(lims)
    ax.set_ylim(lims)
    ax.set_zlim(lims)

   
    
    offset = np.array([0, 0, 0])
    for i, R in enumerate(rotation_matrices):
        plot_rotation_matrix(R, ax, origin=offset, length=1.0, label=f'Matrix {i+1}')
        if axis == 'x':
            offset += np.array([position_diff, 0, 0])
        elif axis == 'y':
            offset += np.array([0, position_diff, 0])
        elif axis == 'z':
            offset += np.array([0, 0, position_diff])

    ax.grid(False)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_zticks([])
    ax.set_xticklabels([])
    ax.set_yticklabels([])
    ax.set_zticklabels([])
    ax.set_xlabel('')
    ax.set_ylabel('')
    ax.set_zlabel('')


    ax.set_box_aspect([1,1,1])  # Set the aspect ratio of the box to be equal
    ax.set_facecolor((1, 1, 1, 1))  # Make the background transparent
    ax.grid(False)  # Hide the grid

    # Hide the panes
    ax.xaxis.pane.fill = False
    ax.yaxis.pane.fill = False
    ax.zaxis.pane.fill = False

    # Hide the box edges
    ax.xaxis.pane.set_edgecolor((1, 1, 1, 1))
    ax.yaxis.pane.set_edgecolor((1, 1, 1, 1))
    ax.zaxis.pane.set_edgecolor((1, 1, 1, 1))

    ax.xaxis._axinfo['grid'].update({'linewidth': 0})
    ax.yaxis._axinfo['grid'].update({'linewidth': 0})
    ax.zaxis._axinfo['grid'].update({'linewidth': 0})




        
    #ax.legend()
    plt.show()



---------------------------------------------------------------------------------------------------------------------


import time
import numpy as np
from ahrs.filters import Madgwick

# Initialize the Madgwick filter
frequency = 200  # Sampling frequency in Hz
madgwick = Madgwick(frequency=frequency)

# Dummy data generation function (replace with your sensor data acquisition method)
def get_sensor_data():
    # Replace this with actual sensor data acquisition
    gyro = np.random.randn(3)  # Replace with actual gyroscope data
    accel = np.random.randn(3)  # Replace with actual accelerometer data
    return gyro, accel

try:
    while True:
        # Get the latest sensor data
        gyr, acc = get_sensor_data()

        # Update the Madgwick filter with the new sensor data
        madgwick.updateIMU(gyr=gyr, acc=acc)

        # Get the current orientation as a quaternion
        orientation = madgwick.Q

        # Print or log the orientation
        print("Current orientation (quaternion):", orientation)

        # Sleep for the sampling interval duration
        time.sleep(1.0 / frequency)

except KeyboardInterrupt:
    print("Real-time processing stopped.")







--------------------------------------------------------------------------------------
import numpy as np
from ahrs.filters import Madgwick
import time

# Example data - Replace these with your actual data
gyro_data = np.random.randn(1000, 3)  # Replace with actual gyroscope data (Nx3 array)
accel_data = np.random.randn(1000, 3)  # Replace with actual accelerometer data (Nx3 array)
frequency = 200  # Sampling frequency in Hz

# Initialize the Madgwick filter
madgwick = Madgwick(frequency=frequency)

# Initialize an array to store the orientation estimates
orientations = np.zeros((len(gyro_data), 4))  # Nx4 array for quaternions

# Simulate real-time frame-by-frame processing
for i in range(len(gyro_data)):
    gyr = gyro_data[i]
    acc = accel_data[i]
    
    # Update the Madgwick filter with the new sensor data
    madgwick.updateIMU(gyr=gyr, acc=acc)
    
    # Store the current orientation as a quaternion
    orientations[i] = madgwick.Q
    
    # Simulate real-time delay
    time.sleep(1.0 / frequency)

# Print the estimated orientations
print("Estimated orientations (quaternions):")
print(orientations)




--------------------------------


import h5py
import numpy as np

def save_to_h5(filename, data):
    """
    Saves a Python data structure to an HDF5 file.

    Parameters:
    - filename: str, the name of the HDF5 file to save the data.
    - data: the data to save, which can be a dictionary, list, NumPy array, or basic data type.
    """
    with h5py.File(filename, 'w') as hf:
        if isinstance(data, dict):
            for key, value in data.items():
                if isinstance(value, np.ndarray):
                    hf.create_dataset(key, data=value)
                else:
                    hf.attrs[key] = value
        elif isinstance(data, list):
            for i, value in enumerate(data):
                if isinstance(value, np.ndarray):
                    hf.create_dataset(str(i), data=value)
                else:
                    hf.attrs[str(i)] = value
        elif isinstance(data, np.ndarray):
            hf.create_dataset('data', data=data)
        else:
            hf.attrs['value'] = data

# Example usage
data_dict = {
    'array': np.array([1, 2, 3]),
    'scalar': 42
}

data_list = [np.array([4, 5, 6]), 'string', 3.14]

save_to_h5('data_dict.h5', data_dict)
save_to_h5('data_list.h5', data_list)



-------------------------------


def save_nested_dict_to_h5(h5file, path, data):
    """
    Recursively saves a nested dictionary to an HDF5 file.

    Parameters:
    - h5file: An open h5py.File object where the data will be stored.
    - path: A string representing the current path in the HDF5 file.
    - data: The data to save, which can be a dictionary, list, NumPy array, or basic data type.
    """
    if isinstance(data, dict):
        for key, value in data.items():
            current_path = f"{path}/{key}"
            save_nested_dict_to_h5(h5file, current_path, value)
    elif isinstance(data, np.ndarray):
        h5file.create_dataset(path, data=data)
    else:
        # Store basic data types as attributes (you can modify this as needed)
        h5file.attrs[path] = data

def save_to_h5(filename, data):
    """
    Saves a Python nested dictionary to an HDF5 file.

    Parameters:
    - filename: str, the name of the HDF5 file to save the data.
    - data: the data to save, which can be a nested dictionary containing NumPy arrays.
    """
    with h5py.File(filename, 'w') as hf:
        save_nested_dict_to_h5(hf, '', data)

# Example usage
data = {
    'imu1': {
        'acce': np.array([1, 2, 3]),
        'mag': np.array([4, 5, 6]),
        'gyro': np.array([7, 8, 9])
    },
    'imu2': {
        'acce': np.array([10, 11, 12]),
        'mag': np.array([13, 14, 15]),
        'gyro': np.array([16, 17, 18])
    }
    # More nested data...
}

save_to_h5('nested_data.h5', data)


------------------------------------------------------
CNN-LSTM
------------------------------------------------------

import torch
import torch.nn as nn
import torch.optim as optim

# Define the CNN-LSTM model
class CNN_LSTM(nn.Module):
    def __init__(self, input_size, cnn_output_size, lstm_hidden_size, num_classes):
        super(CNN_LSTM, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2),
            nn.Dropout(0.3),
            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2),
            nn.Dropout(0.3),
            nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2),
            nn.Dropout(0.3)
        )
        self.lstm = nn.LSTM(input_size=cnn_output_size, hidden_size=lstm_hidden_size, num_layers=2, batch_first=True)
        self.fc = nn.Linear(lstm_hidden_size, num_classes)

    def forward(self, x):
        # x shape: (batch_size, time_steps, input_size)
        batch_size, time_steps, _ = x.size()
        
        # Reshape for CNN: (batch_size, input_size, time_steps)
        x = x.permute(0, 2, 1)
        x = self.cnn(x)
        
        # Reshape for LSTM: (batch_size, time_steps, cnn_output_size)
        x = x.permute(0, 2, 1)
        lstm_out, _ = self.lstm(x)
        
        # Use the last output of the LSTM for classification
        lstm_out = lstm_out[:, -1, :]
        out = self.fc(lstm_out)
        return out

# Define hyperparameters
input_size = 72  # 12 IMUs * 6 features (3-axis accelerometer + 3-axis gyroscope)
cnn_output_size = 512  # Output size from CNN
lstm_hidden_size = 256  # Hidden size of LSTM
num_classes = 22  # Number of joint angles

# Instantiate the model, loss function, and optimizer
model = CNN_LSTM(input_size, cnn_output_size, lstm_hidden_size, num_classes)
criterion = nn.MSELoss()  # Assuming regression task for joint angles
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Example training loop (pseudo code)
for epoch in range(num_epochs):
    for data, labels in data_loader:  # Assuming data_loader provides batches of data
        # Move tensors to the configured device
        data = data.to(device)
        labels = labels.to(device)
        
        # Forward pass
        outputs = model(data)
        loss = criterion(outputs, labels)
        
        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

